{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DC-GAN STEPS","metadata":{}},{"cell_type":"markdown","source":"#### PARAMETERS","metadata":{}},{"cell_type":"code","source":"! pip install imutils\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\nfrom skimage.morphology import convex_hull_image, erosion\nfrom skimage.morphology import square\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom skimage import data, io, filters\nimport skimage\nimport imutils\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"portpath = Path(\"../input/art-portraits/Portraits\")\nportjpg = list(portpath.glob(\"*.jpg\"))\nportseries = pd.Series(portjpg,name=\"JPG\").astype(str)\n\nartpath = Path(\"../input/abstract-paintings/img\")\nartjpg = list(artpath.glob(\"*.jpg\"))\nartseries = pd.Series(artjpg, name=\"JPG\").astype(str)\n\nBrain_Image = []\nfor image_x in portseries[0:10].values:\n    \n    Reading_Image = cv2.cvtColor(cv2.imread(image_x),cv2.COLOR_BGR2RGB)\n    Resized_Image = cv2.resize(Reading_Image,(180,180))\n   \n    Brain_Image.append(Resized_Image)\nprint('port')\n    \nNight_Frame = []\nfor image_x in artseries[0:10].values:\n\n    Reading_Image = cv2.cvtColor(cv2.imread(image_x),cv2.COLOR_BGR2RGB)\n    Resized_Image = cv2.resize(Reading_Image,(180,180))\n   \n    Night_Frame.append(Resized_Image)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Total_List = []\n\nfor brain_x,universe_x in zip(Brain_Image,Night_Frame):\n    Total_List.append(brain_x)\n    Total_List.append(universe_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iterations = 300\nvector_noise_shape = 180 #\ncount_example = 20\nbatch_size = 3\ncount_buffer = 60000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = tf.random.normal([count_example,vector_noise_shape])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### DATA TRANSFORMATION","metadata":{}},{"cell_type":"code","source":"X_Train = np.array(Total_List)\n\nX_Train = X_Train.astype(\"float32\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Train = X_Train[:1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Train = X_Train / 255.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # figure = plt.figure(figsize=(0,1))\n\n# plt.imshow(X_Train[1])\n# plt.xlabel(X_Train[1].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(10,10))\n\nplt.imshow(X_Train[2])\nplt.xlabel(X_Train[2].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TOTAL SHAPE: \",X_Train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TENSOR SLICES","metadata":{}},{"cell_type":"code","source":"# print(Tensor_Data.element_spec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GENERATOR PROCESS","metadata":{}},{"cell_type":"code","source":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Generator = Generator_Model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### DISCRIMINATOR PROCESS","metadata":{}},{"cell_type":"code","source":"def Discriminator_Model():\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    \n    Model.add(Conv2D(128,(3,3),padding=\"same\"))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(1))\n    \n    return Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Discriminator = Discriminator_Model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### OPTIMIZERS","metadata":{}},{"cell_type":"code","source":"Generator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LOSS FUNCTIONS","metadata":{}},{"cell_type":"code","source":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Discriminator_Loss(real_out,fake_out):\n    \n    real_loss_function = Loss_Function(tf.ones_like(real_out),real_out)\n    fake_loss_function = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    total_loss = real_loss_function + fake_loss_function\n    \n    return total_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator_Loss(fake_output):\n    \n    return Loss_Function(tf.ones_like(fake_output),fake_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GENERATING AND SAVING IMAGE","metadata":{}},{"cell_type":"code","source":"def display_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, 0])\n        plt.axis('off')\n\n    plt.savefig('output_image{:04d}.png'.format(epoch))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TRAINING STEP","metadata":{}},{"cell_type":"code","source":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([batch_size,vector_noise_shape])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_Image = Generator(random_noise_vector,training=False)\n        \n        real_output = Discriminator(images,training=True)\n        fake_output = Discriminator(Generator_Fake_Image,training=True)\n        \n        Generator_Loss_Output = Generator_Loss(fake_output)\n        Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TRAINING","metadata":{}},{"cell_type":"code","source":"def Training(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        display_and_save_images(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    display_and_save_images(Generator,epoch,seed)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training(Train_Data,iterations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### PREDICTION","metadata":{}},{"cell_type":"code","source":"Predict_Generator_Noise = tf.random.normal(shape=[50,vector_noise_shape])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(Predict_Generator_Noise))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Generator_Predict = Generator(Predict_Generator_Noise)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(14,14))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_Predict[i]\n    ax.imshow(Prediction_Output,cmap=\"gray\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(14,14))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_Predict[i*2]\n    ax.imshow(Prediction_Output)\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for indexing in range(random.randint(0,50)):\n    figure = plt.figure(figsize=(8,8))\n\n    Saving_Count = indexing\n    plt.axis(\"off\")\n    plt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"hot\")\n    plt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 1\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[1][:,:,0],cmap=\"hot\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 2\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"jet\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 3\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"Spectral\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 4\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"hot\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 4\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"hot\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 6\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count][:,:,0],cmap=\"hot\")\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 7\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 8\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 9\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 10\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 11\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 12\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 13\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 14\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 30\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 31\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 32\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[Saving_Count])\nplt.savefig(f\"Ex{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Output_Path = Path(\"./\")\nOutput_List = list(Output_Path.glob(r\"*.png\"))\nOutput_Series = pd.Series(Output_List,name=\"DCGAN\").astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Output_DCGAN = []\n\nfor image_x in Output_Series:\n    \n    Reading_Img = cv2.cvtColor(cv2.imread(image_x),cv2.COLOR_BGR2RGB)\n    Output_DCGAN.append(Reading_Img)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(8,8))\n\nSaving_Count = 0\nplt.axis(\"off\")\nplt.imshow(Output_DCGAN[Saving_Count])\nplt.savefig(f\"LIST{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(17,17))\n\nSaving_Count = 5\nplt.axis(\"off\")\nplt.imshow(Output_DCGAN[Saving_Count])\nplt.savefig(f\"LIST{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(17,17))\n\nSaving_Count = 6\nplt.axis(\"off\")\nplt.imshow(Output_DCGAN[Saving_Count])\nplt.savefig(f\"LIST{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(17,17))\n\nSaving_Count = 8\nplt.axis(\"off\")\nplt.imshow(Output_DCGAN[Saving_Count])\nplt.savefig(f\"LIST{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure(figsize=(17,17))\n\nSaving_Count = 9\nplt.axis(\"off\")\nplt.imshow(Output_DCGAN[Saving_Count])\nplt.savefig(f\"LIST{Saving_Count}_Output.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
